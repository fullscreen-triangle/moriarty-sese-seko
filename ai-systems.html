<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Systems - Moriarty Documentation</title>
    <link rel="stylesheet" href="docs-styles.css">
</head>
<body>
    <header>
        <nav class="container">
            <div class="logo"><a href="index.html">Moriarty</a></div>
            <ul class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="pipeline.html">Pipeline</a></li>
                <li><a href="orchestration.html">Orchestration</a></li>
                <li><a href="biomechanics.html">Biomechanics</a></li>
                <li><a href="ai-systems.html" class="active">AI Systems</a></li>
            </ul>
        </nav>
    </header>

    <main class="docs-main">
        <div class="container">
            <div class="docs-sidebar">
                <h3>Contents</h3>
                <ul>
                    <li><a href="#overview">Overview</a></li>
                    <li><a href="#llm-training">LLM Training System</a></li>
                    <li><a href="#rag-system">RAG System</a></li>
                    <li><a href="#data-processing">Data Processing</a></li>
                    <li><a href="#api-integration">API Integration</a></li>
                    <li><a href="#examples">Usage Examples</a></li>
                </ul>
            </div>

            <div class="docs-content">
                <h1>AI Systems Integration</h1>
                
                <section id="overview">
                    <h2>Overview</h2>
                    <p>Moriarty integrates cutting-edge AI technologies to enhance sports video analysis through intelligent data processing, natural language interfaces, and automated insights generation. The system combines computer vision outputs with language models to create intuitive, queryable interfaces for biomechanical data.</p>
                    
                    <div class="highlight-box">
                        <h3>ü§ñ AI Components</h3>
                        <ul>
                            <li><strong>LLM Training System:</strong> Convert pose data to natural language for model training</li>
                            <li><strong>RAG System:</strong> Retrieval-Augmented Generation for intelligent querying</li>
                            <li><strong>Data Vectorization:</strong> Embed biomechanical metrics for semantic search</li>
                            <li><strong>Natural Language Interface:</strong> Ask questions about performance in plain English</li>
                            <li><strong>Automated Insights:</strong> Generate performance reports and recommendations</li>
                        </ul>
                    </div>
                </section>

                <section id="llm-training">
                    <h2>LLM Training System</h2>
                    
                    <h3>Architecture Overview</h3>
                    <div class="architecture-diagram">
                        <div class="component-grid">
                            <div class="component-box">
                                <h4>Pose Data Extraction</h4>
                                <p>3D landmarks, confidence scores, temporal sequences</p>
                            </div>
                            <div class="component-box">
                                <h4>Text Conversion</h4>
                                <p>Biomechanical metrics to natural language descriptions</p>
                            </div>
                            <div class="component-box">
                                <h4>Dataset Generation</h4>
                                <p>Training pairs, validation sets, prompt engineering</p>
                            </div>
                            <div class="component-box">
                                <h4>Model Training</h4>
                                <p>Fine-tuning, evaluation, deployment</p>
                            </div>
                        </div>
                    </div>

                    <h3>Data-to-Text Conversion</h3>
                    <div class="code-example">
class BiomechanicalTextGenerator:
    def __init__(self):
        self.templates = self._load_description_templates()
        self.thresholds = self._load_performance_thresholds()
        
    def generate_descriptions(self, analysis_result):
        """
        Convert biomechanical data to natural language descriptions
        
        Args:
            analysis_result: Output from biomechanical analysis
            
        Returns:
            str: Natural language description of performance
        """
        descriptions = []
        
        # Sprint mechanics description
        if hasattr(analysis_result, 'stride_analysis'):
            stride_desc = self._describe_stride_mechanics(
                analysis_result.stride_analysis
            )
            descriptions.append(stride_desc)
            
        # Joint kinematics description
        joint_desc = self._describe_joint_kinematics(
            analysis_result.joint_angles
        )
        descriptions.append(joint_desc)
        
        # Performance summary
        summary = self._generate_performance_summary(analysis_result)
        descriptions.append(summary)
        
        return " ".join(descriptions)
        
    def _describe_stride_mechanics(self, stride_data):
        """Generate description of stride characteristics"""
        length = stride_data['average_length']
        frequency = stride_data['frequency']
        
        length_category = self._categorize_stride_length(length)
        frequency_category = self._categorize_stride_frequency(frequency)
        
        return f"The athlete demonstrates {length_category} stride length " \
               f"averaging {length:.2f} meters with {frequency_category} " \
               f"turnover at {frequency:.1f} strides per second."
               
    def _categorize_stride_length(self, length):
        """Categorize stride length for natural language"""
        if length > 2.5:
            return "exceptional"
        elif length > 2.2:
            return "above-average"
        elif length > 2.0:
            return "average"
        else:
            return "below-average"
                    </div>

                    <h3>Training Pipeline</h3>
                    <div class="pipeline-flow">
                        <div class="pipeline-step">
                            <div class="step-number">1</div>
                            <div class="step-content">
                                <h4>Data Collection</h4>
                                <p>Process videos to extract pose data and biomechanical metrics</p>
                            </div>
                        </div>
                        <div class="pipeline-step">
                            <div class="step-number">2</div>
                            <div class="step-content">
                                <h4>Text Generation</h4>
                                <p>Convert numerical data to natural language descriptions</p>
                            </div>
                        </div>
                        <div class="pipeline-step">
                            <div class="step-number">3</div>
                            <div class="step-content">
                                <h4>Dataset Creation</h4>
                                <p>Format training pairs, create prompts, validation splits</p>
                            </div>
                        </div>
                        <div class="pipeline-step">
                            <div class="step-number">4</div>
                            <div class="step-content">
                                <h4>Model Fine-tuning</h4>
                                <p>Train specialized models on sports biomechanics data</p>
                            </div>
                        </div>
                    </div>

                    <h3>Supported Model Architectures</h3>
                    <div class="tech-specs">
                        <div class="spec-item">
                            <h4>Transformer Models</h4>
                            <ul>
                                <li>GPT-3.5/4 fine-tuning</li>
                                <li>BERT for classification tasks</li>
                                <li>T5 for text-to-text generation</li>
                                <li>Custom sports domain models</li>
                            </ul>
                        </div>
                        <div class="spec-item">
                            <h4>Training Configurations</h4>
                            <ul>
                                <li>Learning rates: 1e-5 to 5e-4</li>
                                <li>Batch sizes: 4-32 (gradient accumulation)</li>
                                <li>Context length: 512-2048 tokens</li>
                                <li>LoRA/QLoRA for efficient fine-tuning</li>
                            </ul>
                        </div>
                        <div class="spec-item">
                            <h4>Evaluation Metrics</h4>
                            <ul>
                                <li>BLEU scores for text quality</li>
                                <li>ROUGE scores for summarization</li>
                                <li>Perplexity for language modeling</li>
                                <li>Domain expert validation</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <section id="rag-system">
                    <h2>RAG System (Retrieval-Augmented Generation)</h2>
                    
                    <h3>System Architecture</h3>
                    <p>The RAG system enables intelligent querying of processed sports videos by combining retrieval of relevant biomechanical data with generative AI responses.</p>
                    
                    <div class="architecture-diagram">
                        <h3>RAG Pipeline Flow</h3>
                        <div class="component-grid">
                            <div class="component-box">
                                <h4>Knowledge Base</h4>
                                <p>Vectorized biomechanical data, pose sequences, performance metrics</p>
                            </div>
                            <div class="component-box">
                                <h4>Query Processing</h4>
                                <p>Natural language to vector embeddings, semantic search</p>
                            </div>
                            <div class="component-box">
                                <h4>Retrieval Engine</h4>
                                <p>Find relevant data segments, rank by similarity</p>
                            </div>
                            <div class="component-box">
                                <h4>Response Generation</h4>
                                <p>Context-aware answers with data citations</p>
                            </div>
                        </div>
                    </div>

                    <h3>Vector Database Integration</h3>
                    <div class="code-example">
class SportsRAGSystem:
    def __init__(self, vector_db_path="./rag_database"):
        self.vector_db = ChromaDB(persist_directory=vector_db_path)
        self.embedding_model = SentenceTransformers('all-MiniLM-L6-v2')
        self.llm = OpenAI(model="gpt-4")
        
    def index_analysis_results(self, video_id, analysis_data):
        """
        Index biomechanical analysis results for retrieval
        
        Args:
            video_id: Unique identifier for the video
            analysis_data: Complete analysis results
        """
        # Generate text descriptions
        descriptions = self._generate_searchable_text(analysis_data)
        
        # Create metadata
        metadata = {
            'video_id': video_id,
            'athlete': analysis_data.get('athlete_name'),
            'sport': analysis_data.get('sport_type'),
            'timestamp': analysis_data.get('timestamp'),
            'max_velocity': analysis_data.get('max_velocity'),
            'stride_frequency': analysis_data.get('stride_frequency')
        }
        
        # Add to vector database
        self.vector_db.add(
            documents=descriptions,
            metadatas=[metadata] * len(descriptions),
            ids=[f"{video_id}_{i}" for i in range(len(descriptions))]
        )
        
    def query(self, question, top_k=5):
        """
        Query the RAG system with natural language
        
        Args:
            question: Natural language question about performance
            top_k: Number of relevant results to retrieve
            
        Returns:
            str: Generated response with context
        """
        # Retrieve relevant context
        results = self.vector_db.query(
            query_texts=[question],
            n_results=top_k
        )
        
        # Format context for LLM
        context = self._format_context(results)
        
        # Generate response
        prompt = f"""
        Based on the following sports performance data, answer the question:
        
        Context: {context}
        
        Question: {question}
        
        Provide a detailed answer with specific metrics when available.
        """
        
        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.choices[0].message.content
                    </div>

                    <h3>Query Examples</h3>
                    <div class="tips-grid">
                        <div class="tip-card">
                            <h4>üèÉ Performance Queries</h4>
                            <ul>
                                <li>"What was the maximum velocity in the sprint?"</li>
                                <li>"How does the stride frequency compare to elite athletes?"</li>
                                <li>"Show me the ground contact time patterns"</li>
                                <li>"Which phase had the highest power output?"</li>
                            </ul>
                        </div>
                        <div class="tip-card">
                            <h4>üìä Comparison Queries</h4>
                            <ul>
                                <li>"Compare left vs right leg mechanics"</li>
                                <li>"How did performance change between trials?"</li>
                                <li>"Find athletes with similar stride patterns"</li>
                                <li>"Show improvement over time"</li>
                            </ul>
                        </div>
                        <div class="tip-card">
                            <h4>üîç Technical Queries</h4>
                            <ul>
                                <li>"Explain the knee angle patterns during stance"</li>
                                <li>"What caused the velocity drop at 80m?"</li>
                                <li>"Analyze the arm swing coordination"</li>
                                <li>"Identify potential injury risk factors"</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <section id="data-processing">
                    <h2>Data Processing & Vectorization</h2>
                    
                    <h3>Embedding Generation</h3>
                    <p>The system converts biomechanical data into vector embeddings for efficient semantic search and retrieval.</p>
                    
                    <div class="code-example">
class BiomechanicalEmbedder:
    def __init__(self):
        self.text_encoder = SentenceTransformers('all-mpnet-base-v2')
        self.numerical_encoder = self._build_numerical_encoder()
        
    def embed_analysis_data(self, analysis_result):
        """
        Create embeddings for biomechanical analysis data
        
        Args:
            analysis_result: Complete analysis output
            
        Returns:
            dict: Combined embeddings for different data types
        """
        embeddings = {}
        
        # Text embeddings from descriptions
        text_desc = self._generate_text_description(analysis_result)
        embeddings['text'] = self.text_encoder.encode(text_desc)
        
        # Numerical embeddings from metrics
        numerical_features = self._extract_numerical_features(analysis_result)
        embeddings['numerical'] = self.numerical_encoder.encode(numerical_features)
        
        # Combined multimodal embedding
        embeddings['combined'] = self._combine_embeddings(
            embeddings['text'], 
            embeddings['numerical']
        )
        
        return embeddings
        
    def _extract_numerical_features(self, analysis_result):
        """Extract key numerical features for embedding"""
        features = []
        
        # Velocity profile features
        if hasattr(analysis_result, 'velocity_profile'):
            features.extend([
                analysis_result.max_velocity,
                analysis_result.avg_velocity,
                analysis_result.velocity_std
            ])
            
        # Stride characteristics
        if hasattr(analysis_result, 'stride_analysis'):
            features.extend([
                analysis_result.stride_analysis['average_length'],
                analysis_result.stride_analysis['frequency'],
                analysis_result.stride_analysis['symmetry_index']
            ])
            
        # Joint angle features (mean, std, range for each joint)
        for joint, angles in analysis_result.joint_angles.items():
            features.extend([
                np.mean(angles),
                np.std(angles),
                np.max(angles) - np.min(angles)
            ])
            
        return np.array(features)
                    </div>
                </section>

                <section id="api-integration">
                    <h2>API Integration</h2>
                    
                    <h3>RESTful API Endpoints</h3>
                    <div class="code-example">
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI(title="Moriarty AI API")

class QueryRequest(BaseModel):
    question: str
    video_ids: list = None
    athlete_filter: str = None

class AnalysisRequest(BaseModel):
    video_path: str
    generate_insights: bool = True
    train_model: bool = False

@app.post("/api/v1/query")
async def query_rag_system(request: QueryRequest):
    """
    Query the RAG system for insights about sports performance
    """
    try:
        # Initialize RAG system
        rag = SportsRAGSystem()
        
        # Apply filters if provided
        if request.video_ids:
            rag.set_video_filter(request.video_ids)
        if request.athlete_filter:
            rag.set_athlete_filter(request.athlete_filter)
            
        # Process query
        response = rag.query(request.question)
        
        return {
            "answer": response,
            "confidence": rag.get_confidence_score(),
            "sources": rag.get_source_citations()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/analyze")
async def analyze_video_with_ai(request: AnalysisRequest):
    """
    Analyze video and optionally generate AI insights
    """
    try:
        # Run biomechanical analysis
        pipeline = VideoPipeline()
        analysis_result = pipeline.process_video(request.video_path)
        
        # Generate AI insights if requested
        insights = None
        if request.generate_insights:
            insights_generator = PerformanceInsightsGenerator()
            insights = insights_generator.generate_insights(analysis_result)
            
        # Add to training data if requested
        if request.train_model:
            llm_trainer = LLMTrainer()
            llm_trainer.add_training_example(analysis_result)
            
        return {
            "analysis": analysis_result.to_dict(),
            "ai_insights": insights,
            "status": "completed"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
                    </div>

                    <h3>WebSocket Integration</h3>
                    <div class="code-example">
@app.websocket("/ws/real-time-analysis")
async def real_time_analysis(websocket: WebSocket):
    """
    Real-time analysis with streaming AI insights
    """
    await websocket.accept()
    
    try:
        while True:
            # Receive frame data
            frame_data = await websocket.receive_json()
            
            # Process frame
            frame_analysis = process_single_frame(frame_data)
            
            # Generate real-time insights
            if frame_analysis.significant_event_detected:
                insight = generate_real_time_insight(frame_analysis)
                await websocket.send_json({
                    "type": "insight",
                    "data": insight,
                    "timestamp": frame_analysis.timestamp
                })
                
            # Send progress update
            await websocket.send_json({
                "type": "progress",
                "frame_number": frame_analysis.frame_number,
                "metrics": frame_analysis.key_metrics
            })
            
    except WebSocketDisconnect:
        print("Client disconnected from real-time analysis")
                    </div>
                </section>

                <section id="examples">
                    <h2>Usage Examples</h2>
                    
                    <h3>Complete AI-Enhanced Analysis Workflow</h3>
                    <div class="code-example">
# Complete AI-enhanced analysis example
from src.ai import LLMTrainer, SportsRAGSystem, PerformanceInsights

# 1. Train domain-specific model
trainer = LLMTrainer(
    base_model="gpt-3.5-turbo",
    training_data_path="./sports_training_data"
)

# Process videos and generate training data
video_paths = ["sprint1.mp4", "sprint2.mp4", "sprint3.mp4"]
for video_path in video_paths:
    # Analyze video
    analysis = pipeline.process_video(video_path)
    
    # Add to training dataset
    trainer.add_analysis_result(analysis)

# Fine-tune the model
trainer.train_model(
    epochs=3,
    learning_rate=1e-4,
    output_dir="./models/sports_llm"
)

# 2. Set up RAG system
rag = SportsRAGSystem()

# Index all analysis results
for video_id, analysis in enumerate(analysis_results):
    rag.index_analysis_results(f"video_{video_id}", analysis)

# 3. Query the system
questions = [
    "Which athlete had the highest top speed?",
    "How does stride frequency correlate with performance?",
    "Identify common technique issues across athletes",
    "Generate training recommendations for improving sprint starts"
]

for question in questions:
    answer = rag.query(question)
    print(f"Q: {question}")
    print(f"A: {answer}\n")

# 4. Generate comprehensive insights
insights_generator = PerformanceInsights(
    model_path="./models/sports_llm"
)

for analysis in analysis_results:
    insights = insights_generator.generate_insights(
        analysis_data=analysis,
        insight_types=['performance', 'technique', 'recommendations']
    )
    
    print(f"Performance Summary: {insights.performance_summary}")
    print(f"Technique Analysis: {insights.technique_analysis}")
    print(f"Recommendations: {insights.recommendations}")
                    </div>

                    <h3>Interactive Query Interface</h3>
                    <div class="code-example">
# Interactive CLI for querying sports data
import cmd

class SportsQueryCLI(cmd.Cmd):
    intro = 'Welcome to Moriarty AI Query System. Type help or ? for commands.'
    prompt = 'moriarty> '
    
    def __init__(self):
        super().__init__()
        self.rag_system = SportsRAGSystem()
        
    def do_query(self, arg):
        """Query the sports database: query What was the fastest sprint time?"""
        if not arg:
            print("Please provide a question to query")
            return
            
        try:
            response = self.rag_system.query(arg)
            print(f"\nAnswer: {response}\n")
        except Exception as e:
            print(f"Error processing query: {e}")
            
    def do_analyze(self, arg):
        """Analyze a new video: analyze path/to/video.mp4"""
        if not arg:
            print("Please provide a video path")
            return
            
        try:
            # Process video
            pipeline = VideoPipeline()
            result = pipeline.process_video(arg)
            
            # Add to RAG system
            video_id = f"video_{len(self.rag_system.get_all_videos())}"
            self.rag_system.index_analysis_results(video_id, result)
            
            print(f"Video analyzed and indexed as {video_id}")
            
        except Exception as e:
            print(f"Error analyzing video: {e}")
            
    def do_compare(self, arg):
        """Compare athletes or videos: compare athlete1 athlete2"""
        athletes = arg.split()
        if len(athletes) != 2:
            print("Please provide exactly two athletes to compare")
            return
            
        question = f"Compare the performance between {athletes[0]} and {athletes[1]}"
        response = self.rag_system.query(question)
        print(f"\nComparison: {response}\n")

if __name__ == '__main__':
    SportsQueryCLI().cmdloop()
                    </div>
                </section>
            </div>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2024 Moriarty Sports Analysis Framework</p>
        </div>
    </footer>
</body>
</html> 